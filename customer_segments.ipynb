{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Customer Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you, will analyze a dataset containing annual spending amounts for internal structure, to understand the variation in the different types of customers that a wholesale distributor interacts with.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Run each code block below by pressing **Shift+Enter**, making sure to implement any steps marked with a TODO.\n",
    "- Answer each question in the space provided by editing the blocks labeled \"Answer:\".\n",
    "- When you are done, submit the completed notebook (.ipynb) with all code blocks executed, as well as a .pdf version (File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 440 rows, 6 columns\n",
      "   Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicatessen\n",
      "0  12669  9656     7561     214              2674          1338\n",
      "1   7057  9810     9568    1762              3293          1776\n",
      "2   6353  8808     7684    2405              3516          7844\n",
      "3  13265  1196     4221    6404               507          1788\n",
      "4  22615  5410     7198    3915              1777          5185\n"
     ]
    }
   ],
   "source": [
    "# Import libraries: NumPy, pandas, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv(\"wholesale-customers.csv\")\n",
    "print \"Dataset has {} rows, {} columns\".format(*data.shape)\n",
    "print data.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** In this section you will be using PCA and ICA to start to understand the structure of the data. Before doing any computations, what do you think will show up in your computations? List one or two ideas for what might show up as the first PCA dimensions, or what type of vectors will show up as ICA dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The first few PCA dimensions will be those that account for the highest proportion of variation in the output. We would expect them to be composed of original features that are correlated in some way: perhaps they are combinations of items that customers tend to purchase together, such as 'fresh' and 'grocery' products. The ICA dimensions will be dimensions that are independent of one another. It seems like 'delicatessen' and 'detergents_paper' are classes that would not be strongly correlated to other classes insofar as customer purchases are concerned, so they would likely show up as ICA dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97653685 -0.12118407 -0.06154039 -0.15236462  0.00705417 -0.06810471]\n",
      " [-0.11061386  0.51580216  0.76460638 -0.01872345  0.36535076  0.05707921]\n",
      " [-0.17855726  0.50988675 -0.27578088  0.71420037 -0.20440987  0.28321747]\n",
      " [-0.04187648 -0.64564047  0.37546049  0.64629232  0.14938013 -0.02039579]\n",
      " [ 0.015986    0.20323566 -0.1602915   0.22018612  0.20793016 -0.91707659]\n",
      " [-0.01576316  0.03349187  0.41093894 -0.01328898 -0.87128428 -0.26541687]]\n",
      "\n",
      "[ 0.45961362  0.40517227  0.07003008  0.04402344  0.01502212  0.00613848]\n",
      "\n",
      "The principal components are orthonormal\n",
      "The principal component matrix is orthogonal\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAESCAYAAAD5d3KwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKnL/weUXh1CP6AK7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d3c59f910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "n = min(data.shape)\n",
    "pca = PCA(n_components=n).fit(data)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print pca.components_\n",
    "print '\\n', pca.explained_variance_ratio_\n",
    "\n",
    "#plot data\n",
    "plt.scatter(xrange(1,n+1), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Dimension', size=12)\n",
    "plt.ylabel('Explained Variance', size=12)\n",
    "plt.ylim(0)\n",
    "\n",
    "# truth table from dot products between each row vector combo as check for orthonormality\n",
    "# note the preparation for rounding errors\n",
    "dot_matrix = [(0.99999999 < sum(pca.components_[i] * pca.components_[j]) < 1.00000001) if j==i #unit vector check\n",
    "              else (abs(sum(pca.components_[i] * pca.components_[j])) < 1e-10) #orthogonality check\n",
    "              for i in xrange(n)\n",
    "              for j in xrange(i,n) ]\n",
    "print '\\nThe principal components are %sorthonormal' % (('not ', '')[all(dot_matrix)])\n",
    "\n",
    "#another way to check for orthonormality of the principal component vectorsis the following: if the principal \n",
    "#components matrix is orthogonal, the principal component vectors within it must be orthonormal.\n",
    "#A matrix is orthogonal if that matrix multiplied by its transpose equals the identity matrix. In other words, a \n",
    "#matrix whose transpose is also its inverse is orthogonal\n",
    "U = np.matrix(pca.components_).T\n",
    "truth_matrix = abs((U.T * U) - np.identity(n)) < np.full((n, n),1e-10)\n",
    "print 'The principal component matrix is %sorthogonal' % (('not ', '')[truth_matrix.all()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** How quickly does the variance drop off by dimension? If you were to use PCA on this dataset, how many dimensions would you choose for your analysis? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "\n",
    "PCA orders its output in terms of explained variance, i.e. the fraction of variance in the data explained by the relationships encoded in each principal component. So we know that the first pricipal component explains more of the variance than any other, the second component more than any other but the first and so on down the line. In our example, the first two principal components account for 46.0% and 40.5% of the variance in the data respectively. In contrast, the third principal component accounts for only 7.0% of the variance. It is clear from the plot above that the explained variance drops off rapidly after the first two components.\n",
    "\n",
    "These results suggest that a total of two principal component dimensions is the ideal number for our data. The first two dimensions explain almost 86.5% of the variance in the data set. Of course we could explain more of the variance by including additional dimensions, but then we run the risk of overfitting and the increase in model variance error that comes with it (variance here refers to the type of modelling error, rather than the distribution of the original data set that we had been discussing earlier). Having said that, the ideal number of two dimensions was arrived at be heuristic means, and the proper way to do it would be to train models with different numbers of dimensions, perhaps using the feature selection technique, then see how they perform on test data. Nevertheless, based only on the analysis at hand, we choose to work with two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** What do the dimensions seem to represent? How can you use this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "\n",
    "The principal component dimensions represent vectors that are linear combinations of the original feature dimensions. In fact, the analysis above shows them to be mutually orthogonal unit vectors. We can think of the six principal component vectors as elements of a principal component matrix, which because the individual vectors within it are orthonormal is orthogonal. This matrix corresponds to a set of six-dimensional orthogonal axes rotated with respect to the original six-dimensional feature axes. The principal components matrix can be applied to an input feature vector to project it onto the principal component axes. Now for our purposes it's not so interesting to take an input, rotate it around in six-dimensional space and see what it looks like when written in terms of a principal component system. But we can see how to extend the concept to execute the highly useful dimensionality reduction discussed in question 2. As opposed to a 6x6 principal component matrix that projects a 6-dimensonal feature vector onto a 6-dimensional principal component space, we can construct a 2x6 principal component matrix that projects a 6-dimensional feature vector onto a 2-dimensional principal component space. Provided this reduced dimensionality principal component space explains a sufficient amount of the variance in the data (which by the analysis above, we know ours does) we can substantially reduce the computational workload a clustering algorithm would be asked to perform without sacrificing much in terms of valuable information. \n",
    "\n",
    "The first principal component dimension has a coefficient of -0.98 for the 'fresh' feature, -0.15 for the 'frozen' feature and so on. It's pretty obvious that the first principal component is predominantly the 'fresh' feature vector rotated a bit away from the original. Despite the answer given to question 1 above, it seems like the 'fresh' feature has become a principle component almost unto itself. And now that we see this, we see the error in our ways that led to the erroneous answer to question 1. There is no reason that the most principal component need elucidate a strong covariance relationship between features. According to the README doc, the 'fresh' feature has the largest variance of any feature, and we attribute this, at least in part, to scale: the shops spend 50% more on average on 'fresh' items than on those from any other category. There is no need for 'fresh' to correlate to any other feature to have a great influence on total variance. There just needs to be a lot of variation from shop to shop on how much they spend on 'fresh' items. We can use this finding to suggest our wholesale distributor client increase marketing on 'fresh' products to shops who don't buy much of it, as there seems to be a great but uneven demand for 'fresh' products across the client's customer base.\n",
    "\n",
    "The second dimension shows what appears to be the type of correlation we initially expected to see, between two or even three of the original features: 'grocery' with coefficient 0.76, 'milk' with coefficient 0.52 and perhaps 'detergents_paper' with coefficient 0.37. This component is much more a composite of multiple features than the first principal component. This is an interesting finding, as it tells us that stores that buy more 'grocery' items tend also to buy more 'milk' items and to some degree more 'detergents_paper' items as well (and they do correlate positively: all coefficients are the same sign: positive). We can use this discovery to encourage our wholesale distributor client to try to increase sales by marketing these items in a synergistic fashion, and to reduce costs by bundling/delivering them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.65203357e-07   1.40433954e-07  -7.74134859e-07  -1.11461596e-05\n",
      "    5.55175206e-07   5.95231239e-06]\n",
      " [ -3.97590618e-06   8.59058328e-07   6.24232403e-07   6.77446468e-07\n",
      "   -2.06101033e-06   1.04342316e-06]\n",
      " [ -2.10589800e-07   1.88727663e-06  -6.41843645e-06  -4.12230621e-07\n",
      "    7.88586022e-07   1.45013212e-06]\n",
      " [  3.86436469e-07   2.19531902e-07   6.00815003e-07   5.22057330e-07\n",
      "   -5.10239101e-07  -1.80925706e-05]\n",
      " [  1.53632693e-07   9.84534859e-06  -5.80984571e-06  -3.63864019e-07\n",
      "    3.31536850e-06  -6.05749699e-06]\n",
      " [ -2.99843192e-07   2.30595406e-06   1.20636760e-05  -1.46257243e-06\n",
      "   -2.82071883e-05  -5.73219911e-06]]\n",
      "\n",
      "The independent component matrix is not orthogonal\n",
      "The independent components are not unit vectors\n",
      "The independent components are not orthogonal\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit an ICA model to the data\n",
    "# Note: Adjust the data to have center at the origin first! <-- this is done automatically during whitening\n",
    "from sklearn.decomposition import FastICA\n",
    "n = min(data.shape)\n",
    "ica = FastICA(n_components=n, random_state=42).fit(data)\n",
    "\n",
    "# Print the independent components\n",
    "print ica.components_\n",
    "\n",
    "#check to see if IC matrix is orthogonal\n",
    "W = np.matrix(ica.components_)\n",
    "truth_matrix = abs((W.T * W) - np.identity(n)) < np.full((n, n),1e-10)\n",
    "print '\\nThe independent component matrix is %sorthogonal' % (('not ', '')[truth_matrix.all()])\n",
    "\n",
    "#check to see if IC's are unit vectors\n",
    "square_matrix = [(0.99999999 < sum(ica.components_[i] * ica.components_[i]) < 1.00000001) \n",
    "              for i in xrange(n) ]\n",
    "print 'The independent components are %sunit vectors' % (('not ', '')[all(square_matrix)])\n",
    "\n",
    "#check to see if IC's are orthogonal\n",
    "cross_matrix =  [(abs(sum(ica.components_[i] * ica.components_[j])) < 1e-10) #orthogonality check\n",
    "              for i in xrange(n)\n",
    "              for j in xrange(i+1,n)]\n",
    "print 'The independent components are %sorthogonal' % (('not ', '')[all(cross_matrix)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** For each vector in the ICA decomposition, write a sentence or two explaining what sort of object or property it corresponds to. What could these components be used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "\n",
    "Contrary to the principal components matrix, the independent components matrix is composed of vectors that are neither of unit length nor mutually orthogonal. The fact that that the independent component vectors are not orthogonal is a direct result of our attempt to make them independent. The fact  they have different lengths suggests that the length of an independent component vector has some meaning. But it is not clear at the present time just what this meaning is.\n",
    "\n",
    "In any case, we can get some idea of what groups of products trend together be looking at the coefficients inside each independent component vector. Within a vector, the magnitude of a coefficient tells us how important the feature to which it corresponds is to that independent component vector. By focusing on the coefficients of greatest magnitude within a vector, we can get an idea of how customers purchase products from different feature groups. If two coefficients have the same sign this implies that sales of the feature items to which they correspond trend together. If they have opposite sign, it implies that customers who buy more from one group buy less from the other. We can utilize this knowledge to better assist our wholesale distributor client optimize marketing strategies to increase sales, perhaps by offering discounts on purchases of one feature group item based on the purchase of another form a different but synergistic feature group. We can also suggest ways to maximize efficiency and cost reduction by bundling delivery of feature items that scale together.\n",
    "\n",
    "The first independent component on the list is composed of something like 2 parts 'frozen', 1 part 'delicatessen' and smaller bits of the other features. Because the coefficients have opposite sign, we see that stores that buy more 'frozen' goods buy less 'delicatessen' goods and vice versa.\n",
    "\n",
    "The second independent component on the list is composed of something like 4 parts 'fresh', 2 parts 'detergents_paper', 1 part 'delicatessen' and smaller bits of the other features. Again because the coefficients, we see that 'fresh' and 'detergents_paper' trend together, whereas 'delicatessen' purchases go down as the others go up.\n",
    "\n",
    "The third independent component on the list is composed of something like 6 parts 'grocery', 2 parts 'milk', 1 part 'delicatessen' and smaller bits of the other features. We see that 'grocery' trends against 'milk' and 'delicatessen'.\n",
    "\n",
    "The fourth independent component on the list is composed of almost entirely 'delicatessen'. 'Delicatessen seems to play an important role in all of the independent components, doesn't it? That might imply that we could segment our customer base into different groups based on how they purchase 'delicatessen' items in relation to other stuff.\n",
    "\n",
    "The fifth independent component on the list is a mixture of a lot of stuff: 10 parts 'milk', 6 parts 'grocery', 6 parts 'delicatessen', 6 parts 'delicatessen', 3 paers 'detergents_paper' and smaller bits of the remaining features. 'Milk' and 'detergents_paper' trend together, as do 'grocery' and 'delicatessen', which of course implies they trend opposite the other two.\n",
    "\n",
    "The sixth independent component on the list is composed of something like 6 parts 'detergents_paper', 2 parts 'grocery', 1 part 'delicatessen' and smaller bits of the other features. 'Detergents_paper' trends with 'delicatessen' and against 'grocery'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clustering\n",
    "\n",
    "In this section you will choose either K Means clustering or Gaussian Mixed Models clustering, which implements expectation-maximization. Then you will sample elements from the clusters to understand their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Choose a Cluster Type\n",
    "\n",
    "**5)** What are the advantages of using K Means clustering or Gaussian Mixture Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "[K Means clustering](http://scikit-learn.org/stable/modules/clustering.html#k-means) is a quick and conceptually straightforward algorithm for clustering data. It works well when the data clusters are relatively simple in shape, like Gaussian hyperspheres, but can struggle to identify clusters properly when the clusters have more complex non-linear geometries.\n",
    "\n",
    "[Gaussian Mixture Models](http://scikit-learn.org/stable/modules/mixture.html) is an generalization of K Means clustering that takes into account the covariance of the data. It os very fast, and it does not presume the data has a specific structure that may in fact not be applicable.\n",
    "\n",
    "Gaussian Mixture Models is a better choice, simply because it presumes less than K Means Clustering about the structure of the data. So this is the model that we will use.\n",
    "\n",
    "Notice that both of these models presume more or less that the data are Gaussian distributed. This is at odds with the Independent Components Analysis, which presumes that the data are certainly not Gaussian distributed. For this reason, we will not be using ICA for preprocessing. We will use PCA instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Below is some starter code to help you visualize some cluster data. The visualization is based on [this demo](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) from the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import clustering modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14112.07286824  10409.72068096]\n",
      " [ -9035.2457668   12866.65309972]\n",
      " [ -8620.05203937  11402.96376688]\n",
      " [-14452.39718306   2544.39559425]\n",
      " [-24120.04947733   6664.4757757 ]\n",
      " [-10696.08915346   7864.33086375]\n",
      " [-12746.49985397   6811.19932521]\n",
      " [ -8987.4670792   10253.69856292]\n",
      " [ -6749.95534899   6618.2924349 ]\n",
      " [ -8638.4163921   22304.76079577]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: First we reduce the data to two dimensions using PCA to capture variation\n",
    "PCMatrix = PCA(n_components=2).fit(data).components_\n",
    "reduced_data = np.dot(data, PCMatrix.T)\n",
    "print reduced_data[:10]  # print up to 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM(covariance_type='diag', init_params='wmc', min_covar=0.001,\n",
      "  n_components=8, n_init=1, n_iter=100, params='wmc', random_state=42,\n",
      "  thresh=None, tol=0.001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your clustering algorithm here, and fit it to the reduced data for visualization\n",
    "# The visualizer below assumes your clustering object is named 'clusters'\n",
    "# find best-performing gmm model using an ad-hoc grid-search approach with BIC as metric\n",
    "# adapted from \n",
    "# http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html#example-mixture-plot-gmm-selection-py\n",
    "lowest_BIC = np.infty\n",
    "for n_components in xrange(1,11):\n",
    "    for covariance_type in ('spherical', 'tied', 'diag', 'full'):\n",
    "        gmm = GMM(n_components, covariance_type, random_state=42)\n",
    "        this_clustering = gmm.fit(reduced_data)\n",
    "        this_BIC = gmm.bic(reduced_data)\n",
    "        if this_BIC < lowest_BIC:\n",
    "            lowest_BIC, clusters = this_BIC, gmm\n",
    "\n",
    "print clusters.fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 samples in Cluster 0\n",
      "Here is what a typical Cluster 0 customers buys from the wholesale distributor:\n",
      "Fresh                2149.674699\n",
      "Milk                 7534.144578\n",
      "Grocery             12095.048193\n",
      "Frozen               1297.361446\n",
      "Detergents_Paper     5258.325301\n",
      "Delicatessen         1244.012048\n",
      "dtype: float64 \n",
      "\n",
      "There are 122 samples in Cluster 1\n",
      "Here is what a typical Cluster 1 customers buys from the wholesale distributor:\n",
      "Fresh               12426.024590\n",
      "Milk                 1572.221311\n",
      "Grocery              1984.680328\n",
      "Frozen               3645.377049\n",
      "Detergents_Paper      340.131148\n",
      "Delicatessen          801.868852\n",
      "dtype: float64 \n",
      "\n",
      "There are 77 samples in Cluster 2\n",
      "Here is what a typical Cluster 2 customers buys from the wholesale distributor:\n",
      "Fresh               18608.415584\n",
      "Milk                 6437.207792\n",
      "Grocery              8283.792208\n",
      "Frozen               3945.909091\n",
      "Detergents_Paper     2191.766234\n",
      "Delicatessen         2110.493506\n",
      "dtype: float64 \n",
      "\n",
      "There are 9 samples in Cluster 3\n",
      "Here is what a typical Cluster 3 customers buys from the wholesale distributor:\n",
      "Fresh               25043.666667\n",
      "Milk                37154.000000\n",
      "Grocery             47115.111111\n",
      "Frozen               6627.333333\n",
      "Detergents_Paper    20716.444444\n",
      "Delicatessen         9478.888889\n",
      "dtype: float64 \n",
      "\n",
      "There are 28 samples in Cluster 4\n",
      "Here is what a typical Cluster 4 customers buys from the wholesale distributor:\n",
      "Fresh               41873.035714\n",
      "Milk                 2548.857143\n",
      "Grocery              3664.535714\n",
      "Frozen               5375.642857\n",
      "Detergents_Paper      693.035714\n",
      "Delicatessen         1991.428571\n",
      "dtype: float64 \n",
      "\n",
      "There is 1 sample in Cluster 5\n",
      "Here is what the Cluster 5 customer buys from the wholesale distributor:\n",
      "Fresh               112151\n",
      "Milk                 29627\n",
      "Grocery              18148\n",
      "Frozen               16745\n",
      "Detergents_Paper      4948\n",
      "Delicatessen          8550\n",
      "dtype: float64 \n",
      "\n",
      "There are 84 samples in Cluster 6\n",
      "Here is what a typical Cluster 6 customers buys from the wholesale distributor:\n",
      "Fresh               4492.607143\n",
      "Milk                2753.297619\n",
      "Grocery             3317.571429\n",
      "Frozen              2250.166667\n",
      "Detergents_Paper     720.976190\n",
      "Delicatessen        1055.988095\n",
      "dtype: float64 \n",
      "\n",
      "There are 36 samples in Cluster 7\n",
      "Here is what a typical Cluster 7 customers buys from the wholesale distributor:\n",
      "Fresh                7375.472222\n",
      "Milk                15858.027778\n",
      "Grocery             21978.416667\n",
      "Frozen               2207.638889\n",
      "Detergents_Paper     9716.416667\n",
      "Delicatessen         1917.527778\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identify which customers are in which cluster\n",
    "x = data['Cluster'] = clusters.predict(reduced_data)\n",
    "\n",
    "# print cluster sample counts and averages\n",
    "for i in xrange(clusters.n_components):\n",
    "    count = data[x==i].shape[0]\n",
    "    print 'There %s %s sample%s in Cluster %s' % (('is', 'are')[count>1], count, ('', 's')[count>1], i)\n",
    "    print 'Here is what %s Cluster %s customer%s buys from the wholesale distributor:' % (\n",
    "        ('the', 'a typical')[count>1], i, ('','s')[count>1])\n",
    "    print data[x==i][list(data.columns[:-1])].mean(),'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary by building a mesh grid to populate a graph.\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "hx = (x_max-x_min)/1000.\n",
    "hy = (y_max-y_min)/1000.\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = clusters.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -4058.55883796   14247.16721981]\n",
      " [ -13007.08613801    1162.68366073]\n",
      " [ -19022.98339065    7791.09810257]\n",
      " [ -33154.02804526   54512.9623942 ]\n",
      " [ -39822.67630219     411.02519907]\n",
      " [-117325.47606621   18734.55121945]\n",
      " [  -5925.19361093    3552.54609579]\n",
      " [ -10690.43525617   23789.07516358]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the centroids for KMeans or the cluster means for GMM \n",
    "centroids = clusters.means_\n",
    "print centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAF7CAYAAADWulHTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAg8AAIi9/w8nrv0HvLCaAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d2d7aa450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1,figsize=(10,6))\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=100, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('Clustering on the wholesale grocery dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** What are the central objects in each cluster? Describe them as customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "\n",
    "The graph above shows the customer data plotted in terms of the first principal component along the x-axis and the second principal component along the y-axis. The various colors represent the optimal clusterings.\n",
    "\n",
    "Recall from question 2 that the first principal component is predominantly the negative of the 'fresh' category, and that the second principal component is an amalgamation of 'grocery', 'milk' and a bit of 'detergents_paper' (hereafter known as 'GMDP'), all positive. Since the x-axis shows negative values, the larger magnitudes are to the left.\n",
    "\n",
    "The number of clusters was determined by an ad-hoc grid search using Bayesian Information Criteria (BIC) above, Details of the clusters, including sample size and average purchases by product group were provided earlier. Here we discuss them in terms of the plot immediately above, and introduce a bit of conjecture as to what type of businesses these customers might be.\n",
    "\n",
    "Cluster 0: the small customers that buy mostly 'GMDP' and don't buy much 'Fresh' or other products, shown in the graph as a vertical sky blue oval in the lower right. These might be convenience stores and corner markets.\n",
    "\n",
    "Cluster 1: the small customers that buy mostly 'Fresh' and don't buy much 'GMDP' or other products, shown in the graph as a long and narrow bluish green horizontal oval in the lower right. These might be delis and single-outlet fast food shops.\n",
    "\n",
    "Cluster 2: the mid-sized customers that buy mostly 'Fresh' but also buy a good amount of 'GMDP' and other products, shown in the graph as the large greenish spearhead shape. These might be larger restaurants.\n",
    "\n",
    "Cluster 3: the customers who tend to buy lots of both 'fresh' and 'GMDP', whose area takes up most of the diagram and is shown in red. These customers might be big-box retailers who sell a wide variety of products in bulk.\n",
    "\n",
    "Cluster 4: the large customers who tend to buy mostly 'fresh' products, shown along the bottom toward the left in orange. These might be cafeterias belonging to large corporations, schools or the government (military bases, prisons, etc.).\n",
    "\n",
    "Cluster 5: a singe customer that buys a huge amount of 'Fresh' products. It does not have a corresponding area on the color map, but is represented by the white cross at the extreme left. It might a regional distribution center for a national fast food chain.\n",
    "\n",
    "Cluster 6: the small customers that buy mostly 'Fresh' as well as a decent amount of 'GMDP' or other products, shown in the graph as the lavender spearhead shape in the lower right. These might be delis and single-outlet fast food shops, similar to Cluster 1 customers but perhaps serving different neighborhoods or customer bases.\n",
    "\n",
    "Cluster 7: the mid sized customers that tend to buy predominantly 'GMDP' products, shown as the occluded brown semi-egg at right. These might be mid sized single-outlet grocery stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conclusions\n",
    "\n",
    "**8)** Which of these techniques did you feel gave you the most insight into the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "\n",
    "It seems that the Gaussian Mixture Model helped a lot to make sense out of the data. It tended to identify customer groups that lent themselves to easy (and hopefully correct) interpretation. We suspect it has done a better job at elucidating these details then K Means would, as we would not expect K Means to identify the long and narrow clusters that are nicely picked out by the Gaussian Mixture Model. Of course, all this was enabled by PCA which did an excellent job of collapsing six dimensions of data down to a convenient but still highly informative two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**9)** How would you use that technique to help the company design new experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The original problem that our wholesale distributor client has was that when they adjusted their delivery schedule, smallee customers like those in Groups 1 and 4 complained that it did not suit their schedule. But these complaints did not register during the trial phase of the new delivery system, presumably because our client focused on the larger customers, like those in Groups 3 and 6, who had no issue with the new delivery system.\n",
    "\n",
    "Now that we have demonstrated a method of categorizing our client's customers based on what they purchase and how much of it, we can propose modifications and improvements to our client's delivery and marketing strategies that are tailored to a customer group. For example, while a low-cost bulk nightly delivery schedule was not acceptable to our customer's smaller clients, we could propose experiments to identify reduced cost delivery methods that would be acceptable to these customery, perhaps a bulk delivery system in the early business hours. We could also run some marketing experiments, like offering discounts on 'milk' products to customers who buy a lot of 'grocery' products to leverage product synergies and increase overall sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** How would you use that data to help you predict future customer needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "We could track product group purchases over time by customer group, for which we could use the supervised learning technique of regression. For example, perhaps we would uncover a trend that suggests sales of 'frozen' products are decreasing over time in favor of 'fresh' products. We could alert our wholesale distributor to this trend in advance such that they could proactively prepare for a shift in customer demand. We could look deeply into the data to see if this was a universal trend, or if it affected only a subset of customer groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
